{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we shal train a recurrent neural network on the [Cornell Movie dataset](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded the dataset!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Create the data folder if it doesn't exist\n",
    "if not os.path.exists(\"./data/\"):\n",
    "    os.makedirs('./data/')\n",
    "\n",
    "# Download the dataset\n",
    "url = 'http://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip'\n",
    "file_name = './data/{}'.format(os.path.basename(url))\n",
    "\n",
    "request = urlopen(url)\n",
    "data = request.read()\n",
    "\n",
    "with open(file_name, 'wb') as file:\n",
    "    file.write(data)\n",
    "\n",
    "# Unzip the dataset\n",
    "with ZipFile(file_name, 'r') as zf:\n",
    "    with zf.open('cornell movie-dialogs corpus/movie_conversations.txt', 'r') as source:\n",
    "        with open('./data/movie_conversations.txt', 'wb') as target:\n",
    "            target.write(source.read())\n",
    "    with zf.open('cornell movie-dialogs corpus/movie_lines.txt', 'r') as source:\n",
    "        with open('./data/movie_lines.txt', 'wb') as target:\n",
    "            target.write(source.read())\n",
    "\n",
    "# Delete the zip file\n",
    "os.remove(file_name)\n",
    "\n",
    "print('Downloaded the dataset!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting all the dialogues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here we have to join both text files in order to generate a list of all dialogues in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['L194', 'L195', 'L196', 'L197'], ['L198', 'L199'], ['L200', 'L201', 'L202', 'L203'], ['L204', 'L205', 'L206'], ['L207', 'L208']]\n"
     ]
    }
   ],
   "source": [
    "# Get all the sequence of conversations from the dataset\n",
    "with open('./data/movie_conversations.txt', 'rt') as file:\n",
    "    movie_conversations = [line.split(' +++$+++ ') for line in file.read().split('\\n')]\n",
    "    movie_conversations = [eval(line[3]) for line in movie_conversations if len(line) == 4]\n",
    "    \n",
    "print(movie_conversations[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['L1045', 'They do not!'], ['L1044', 'They do to!'], ['L985', 'I hope so.'], ['L984', 'She okay?'], ['L925', \"Let's go.\"]]\n"
     ]
    }
   ],
   "source": [
    "# Get all the movie lines from the dataset\n",
    "with open('./data/movie_lines.txt', 'rt') as file:\n",
    "    movie_lines = [line.split(' +++$+++ ') for line in file.read().split('\\n')]\n",
    "    movie_lines = [[line[0], line[4]] for line in movie_lines if len(line) == 5]\n",
    "\n",
    "print(movie_lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('L232180', 'Yessir!'), ('L234880', \"Very nice.  I'll pay you for tonight as well.\"), ('L233686', 'Assuming I go along with this, when can I have the five hundred?'), ('L576816', 'Calm down.  I found it!'), ('L14769', \"But your Grandfather lives in your house. I've seen him.\")]\n"
     ]
    }
   ],
   "source": [
    "# Transform the movie lines in a dictionary by the line ID\n",
    "lines_dict = {id: line for id, line in movie_lines}\n",
    "\n",
    "print(list(lines_dict.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.', \"Well, I thought we'd start with pronunciation, if that's okay with you.\", 'Not the hacking and gagging and spitting part.  Please.', \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\"], [\"You're asking me out.  That's so cute. What's your name again?\", 'Forget it.'], [\"No, no, it's my fault -- we didn't have a proper introduction ---\", 'Cameron.', \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\", 'Seems like she could get a date easy enough...']]\n"
     ]
    }
   ],
   "source": [
    "# Convert the conversations with their proper lines\n",
    "movie_dialogues = [[lines_dict[id] for id in line] for line in movie_conversations]\n",
    "\n",
    "print(movie_dialogues[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to replace tokens from some text\n",
    "def replace_tokens(text):\n",
    "    text = text.replace('.', ' <PERIOD> ')\n",
    "    text = text.replace(',', ' <COMMA> ')\n",
    "    text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
    "    text = text.replace(';', ' <SEMICOLON> ')\n",
    "    text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
    "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
    "    text = text.replace('()', ' <LEFT_PAREN> ')\n",
    "    text = text.replace(')', ' <RIGHT_PAREN> ')\n",
    "    text = text.replace('--', ' <HYPHENS> ')\n",
    "    text = text.replace(':', ' <COLON> ')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['can we make this quick <QUESTION_MARK>   roxanne korrine and andrew barrett are having an incredibly horrendous public break- up on the quad <PERIOD>   again <PERIOD> ', \"well <COMMA>  i thought we'd start with pronunciation <COMMA>  if that's okay with you <PERIOD> \", 'not the hacking and gagging and spitting part <PERIOD>   please <PERIOD> ', \"okay <PERIOD>  <PERIOD>  <PERIOD>  then how 'bout we try out some french cuisine <PERIOD>   saturday <QUESTION_MARK>   night <QUESTION_MARK> \"], [\"you're asking me out <PERIOD>   that's so cute <PERIOD>  what's your name again <QUESTION_MARK> \", 'forget it <PERIOD> '], [\"no <COMMA>  no <COMMA>  it's my fault  <HYPHENS>  we didn't have a proper introduction  <HYPHENS> -\", 'cameron <PERIOD> ', \"the thing is <COMMA>  cameron  <HYPHENS>  i'm at the mercy of a particularly hideous breed of loser <PERIOD>   my sister <PERIOD>   i can't date until she does <PERIOD> \", 'seems like she could get a date easy enough <PERIOD>  <PERIOD>  <PERIOD> ']]\n"
     ]
    }
   ],
   "source": [
    "# Lower the case and replace the tokens from all dialogues\n",
    "movie_dialogues = [[replace_tokens(line.lower()) for line in dialogue] for dialogue in movie_dialogues]\n",
    "\n",
    "print(movie_dialogues[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to create a vocabulary of all the words on the dialogues so that we can convert all words to their proper ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['can', 'we', 'make', 'this', 'quick', '<QUESTION_MARK>', 'roxanne', 'korrine', 'and', 'andrew', 'barrett', 'are', 'having', 'an', 'incredibly', 'horrendous', 'public', 'break-', 'up', 'on', 'the', 'quad', '<PERIOD>', 'again', '<PERIOD>', 'well', '<COMMA>', 'i', 'thought', \"we'd\", 'start', 'with', 'pronunciation', '<COMMA>', 'if', \"that's\", 'okay', 'with', 'you', '<PERIOD>', 'not', 'the', 'hacking', 'and', 'gagging', 'and', 'spitting', 'part', '<PERIOD>', 'please', '<PERIOD>', 'okay', '<PERIOD>', '<PERIOD>', '<PERIOD>', 'then', 'how', \"'bout\", 'we', 'try', 'out', 'some', 'french', 'cuisine', '<PERIOD>', 'saturday', '<QUESTION_MARK>', 'night', '<QUESTION_MARK>', \"you're\", 'asking', 'me', 'out', '<PERIOD>', \"that's\", 'so', 'cute', '<PERIOD>', \"what's\", 'your', 'name', 'again', '<QUESTION_MARK>', 'forget', 'it', '<PERIOD>', 'no', '<COMMA>', 'no', '<COMMA>', \"it's\", 'my', 'fault', '<HYPHENS>', 'we', \"didn't\", 'have', 'a', 'proper', 'introduction', '<HYPHENS>', '-', 'cameron', '<PERIOD>', 'the', 'thing', 'is', '<COMMA>', 'cameron', '<HYPHENS>', \"i'm\", 'at', 'the', 'mercy', 'of', 'a', 'particularly', 'hideous', 'breed', 'of', 'loser', '<PERIOD>', 'my', 'sister', '<PERIOD>', 'i', \"can't\", 'date', 'until', 'she', 'does', '<PERIOD>', 'seems', 'like', 'she', 'could', 'get', 'a', 'date', 'easy', 'enough', '<PERIOD>', '<PERIOD>', '<PERIOD>', 'why', '<QUESTION_MARK>', 'unsolved', 'mystery', '<PERIOD>', 'she', 'used', 'to', 'be', 'really', 'popular', 'when', 'she', 'started', 'high', 'school', '<COMMA>', 'then', 'it', 'was', 'just', 'like', 'she', 'got', 'sick', 'of', 'it', 'or', 'something', '<PERIOD>', \"that's\", 'a', 'shame', '<PERIOD>', 'gosh', '<COMMA>', 'if', 'only', 'we', 'could', 'find', 'kat', 'a', 'boyfriend', '<PERIOD>', '<PERIOD>', '<PERIOD>', 'let', 'me', 'see', 'what', 'i', 'can', 'do', '<PERIOD>', \"c'esc\"]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all text\n",
    "all_lines = ' '.join([' '.join([line for line in dialogue]) for dialogue in movie_dialogues])\n",
    "\n",
    "# Get all words\n",
    "words = all_lines.split()\n",
    "\n",
    "print(words[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the unique words\n",
    "words_set = set(words)\n",
    "\n",
    "# Create the vocabularys\n",
    "vocab_to_int = {word: id for word, id in zip(words_set, range(4, len(words_set) + 4))}\n",
    "vocab_to_int['<PAD>'] = 0\n",
    "vocab_to_int['<EOS>'] = 1\n",
    "vocab_to_int['<UNK>'] = 2\n",
    "vocab_to_int['<GO>'] = 3\n",
    "\n",
    "int_to_vocab = {id: word for word, id in vocab_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in te vocabulary: 65192\n"
     ]
    }
   ],
   "source": [
    "# Get total number of words in the vocabulary\n",
    "n_words = len(vocab_to_int)\n",
    "\n",
    "print('Number of words in te vocabulary: {}'.format(n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[63475, 4265, 41047, 21910, 50558, 14069, 41195, 43613, 9346, 52517, 62031, 1537, 45477, 21283, 62859, 57142, 24004, 48164, 37735, 39572, 30951, 9695, 35094, 22643, 35094], [61522, 49012, 14437, 40312, 56225, 52842, 27384, 16114, 49012, 45569, 54474, 17732, 27384, 27691, 35094], [39356, 30951, 14662, 9346, 38497, 9346, 23667, 10980, 35094, 38558, 35094], [17732, 35094, 35094, 35094, 32041, 63547, 30716, 4265, 22854, 6323, 42316, 49566, 19162, 35094, 35524, 14069, 50342, 14069]], [[726, 55665, 20369, 6323, 35094, 54474, 27821, 28714, 35094, 30590, 60410, 25750, 22643, 14069], [29982, 23201, 35094]], [[41473, 49012, 41473, 49012, 39620, 63696, 11124, 40066, 4265, 39370, 32326, 57578, 40469, 6005, 40066, 18724], [38220, 35094], [30951, 34513, 19680, 49012, 38220, 40066, 51219, 23001, 30951, 58788, 196, 57578, 9153, 34746, 11289, 196, 13536, 35094, 63696, 47119, 35094, 14437, 10307, 50473, 63283, 31216, 57451, 35094], [37916, 29849, 31216, 62332, 64610, 57578, 50473, 45815, 53378, 35094, 35094, 35094]]]\n"
     ]
    }
   ],
   "source": [
    "# Convert the words in all dialogues to their ids\n",
    "movie_dialogues_int = [[[vocab_to_int[word] for word in line.split()] for line in dialogue] for dialogue in movie_dialogues]\n",
    "\n",
    "print(movie_dialogues_int[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "what just happened <QUESTION_MARK> \n",
      "your daughters went to the prom <PERIOD> \n",
      "did i have anything to say about it <QUESTION_MARK> \n",
      "absolutely not <PERIOD> \n",
      "that ' s what i thought\n"
     ]
    }
   ],
   "source": [
    "for line in movie_dialogues[200]:\n",
    "    print(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Separate inputs and targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In here we are going to construct the inputs and targets for the neural network. The inputs are going to be all the lines from the conversation, except the last one. And the targets are going to be all the lines starting by the second forward.\n",
    "\n",
    "For example, imagine if we have the following conversation:\n",
    "\n",
    "    what just happened?\n",
    "    your daughters went to the prom.\n",
    "    did i have anything to say about it? \n",
    "    absolutely not.\n",
    "    that ' s what i thought\n",
    "    \n",
    "The inputs would look like this:\n",
    "\n",
    "    [['what', 'just', 'happened', '<QUESTION_MARK>'],\n",
    "     ['your', 'daughters', 'went', 'to', 'the', 'prom', '<PERIOD>'],\n",
    "     ['did', 'i', 'have', 'anything', 'to', 'say', 'about', 'it', '<QUESTION_MARK>'],\n",
    "     ['absolutely', 'not', '<PERIOD>']]\n",
    "\n",
    "And the targets would look like this:\n",
    "\n",
    "    [['your', 'daughters', 'went', 'to', 'the', 'prom', '<PERIOD>'],\n",
    "     ['did', 'i', 'have', 'anything', 'to', 'say', 'about', 'it', '<QUESTION_MARK>'],\n",
    "     ['absolutely', 'not', '<PERIOD>'],\n",
    "     ['that's', 'what', 'i', 'thought']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = []\n",
    "targets = []\n",
    "\n",
    "for dialogue in movie_dialogues_int:\n",
    "    for line in dialogue[:-1]:\n",
    "        inputs.append(line)\n",
    "    for line in dialogue[1:]:\n",
    "        targets.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61522, 49012, 14437, 40312, 56225, 52842, 27384, 16114, 49012, 45569, 54474, 17732, 27384, 27691, 35094]\n"
     ]
    }
   ],
   "source": [
    "print(inputs[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[61522,\n",
       " 49012,\n",
       " 14437,\n",
       " 40312,\n",
       " 56225,\n",
       " 52842,\n",
       " 27384,\n",
       " 16114,\n",
       " 49012,\n",
       " 45569,\n",
       " 54474,\n",
       " 17732,\n",
       " 27384,\n",
       " 27691,\n",
       " 35094]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
