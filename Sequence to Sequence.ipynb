{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequence to Sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project we shal train a recurrent neural network on the [Cornell Movie dataset](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded the dataset!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from zipfile import ZipFile\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Create the data folder if it doesn't exist\n",
    "if not os.path.exists(\"./data/\"):\n",
    "    os.makedirs('./data/')\n",
    "\n",
    "# Download the dataset\n",
    "url = 'http://www.mpi-sws.org/~cristian/data/cornell_movie_dialogs_corpus.zip'\n",
    "file_name = './data/{}'.format(os.path.basename(url))\n",
    "\n",
    "request = urlopen(url)\n",
    "data = request.read()\n",
    "\n",
    "with open(file_name, 'wb') as file:\n",
    "    file.write(data)\n",
    "\n",
    "# Unzip the dataset\n",
    "with ZipFile(file_name, 'r') as zf:\n",
    "    with zf.open('cornell movie-dialogs corpus/movie_conversations.txt', 'r') as source:\n",
    "        with open('./data/movie_conversations.txt', 'wb') as target:\n",
    "            target.write(source.read())\n",
    "    with zf.open('cornell movie-dialogs corpus/movie_lines.txt', 'r') as source:\n",
    "        with open('./data/movie_lines.txt', 'wb') as target:\n",
    "            target.write(source.read())\n",
    "\n",
    "# Delete the zip file\n",
    "os.remove(file_name)\n",
    "\n",
    "print('Downloaded the dataset!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['L194', 'L195', 'L196', 'L197'], ['L198', 'L199'], ['L200', 'L201', 'L202', 'L203'], ['L204', 'L205', 'L206'], ['L207', 'L208']]\n"
     ]
    }
   ],
   "source": [
    "# Get all the sequence of conversations from the dataset\n",
    "with open('./data/movie_conversations.txt', 'rt') as file:\n",
    "    movie_conversations = [line.split(' +++$+++ ') for line in file.read().split('\\n')]\n",
    "    movie_conversations = [eval(line[3]) for line in movie_conversations if len(line) == 4]\n",
    "    \n",
    "print(movie_conversations[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['L1045', 'They do not!'], ['L1044', 'They do to!'], ['L985', 'I hope so.'], ['L984', 'She okay?'], ['L925', \"Let's go.\"]]\n"
     ]
    }
   ],
   "source": [
    "# Get all the movie lines from the dataset\n",
    "with open('./data/movie_lines.txt', 'rt') as file:\n",
    "    movie_lines = [line.split(' +++$+++ ') for line in file.read().split('\\n')]\n",
    "    movie_lines = [[line[0], line[4]] for line in movie_lines if len(line) == 5]\n",
    "\n",
    "print(movie_lines[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('L215151', \"We have to tell her she's in danger!\"), ('L377268', \"Guys who'll come after her. Guys who'll want to know what happened to her boyfriend. They'll want to make somebody pay. Maybe she'll try and make it you.\"), ('L446344', \"I'll make one for you.  I live there.\"), ('L8052', 'I love to dream, I just hate ones about my dad.'), ('L496795', \"But you're happy here -- you like your work â€”-\")]\n"
     ]
    }
   ],
   "source": [
    "# Transform the movie lines in a dictionary by the line ID\n",
    "lines_dict = {id: line for id, line in movie_lines}\n",
    "\n",
    "print(list(lines_dict.items())[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.', \"Well, I thought we'd start with pronunciation, if that's okay with you.\", 'Not the hacking and gagging and spitting part.  Please.', \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\"], [\"You're asking me out.  That's so cute. What's your name again?\", 'Forget it.'], [\"No, no, it's my fault -- we didn't have a proper introduction ---\", 'Cameron.', \"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\", 'Seems like she could get a date easy enough...']]\n"
     ]
    }
   ],
   "source": [
    "# Convert the conversations with their proper lines\n",
    "movie_dialogues = [[lines_dict[id] for id in line] for line in movie_conversations]\n",
    "\n",
    "print(movie_dialogues[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function to replace tokens from some text\n",
    "def replace_tokens(text):\n",
    "    text = text.replace('.', ' <PERIOD> ')\n",
    "    text = text.replace(',', ' <COMMA> ')\n",
    "    text = text.replace('\"', ' <QUOTATION_MARK> ')\n",
    "    text = text.replace(';', ' <SEMICOLON> ')\n",
    "    text = text.replace('!', ' <EXCLAMATION_MARK> ')\n",
    "    text = text.replace('?', ' <QUESTION_MARK> ')\n",
    "    text = text.replace('()', ' <LEFT_PAREN> ')\n",
    "    text = text.replace(')', ' <RIGHT_PAREN> ')\n",
    "    text = text.replace('--', ' <HYPHENS> ')\n",
    "    text = text.replace(':', ' <COLON> ')\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['can we make this quick <QUESTION_MARK>   roxanne korrine and andrew barrett are having an incredibly horrendous public break- up on the quad <PERIOD>   again <PERIOD> ', \"well <COMMA>  i thought we'd start with pronunciation <COMMA>  if that's okay with you <PERIOD> \", 'not the hacking and gagging and spitting part <PERIOD>   please <PERIOD> ', \"okay <PERIOD>  <PERIOD>  <PERIOD>  then how 'bout we try out some french cuisine <PERIOD>   saturday <QUESTION_MARK>   night <QUESTION_MARK> \"], [\"you're asking me out <PERIOD>   that's so cute <PERIOD>  what's your name again <QUESTION_MARK> \", 'forget it <PERIOD> '], [\"no <COMMA>  no <COMMA>  it's my fault  <HYPHENS>  we didn't have a proper introduction  <HYPHENS> -\", 'cameron <PERIOD> ', \"the thing is <COMMA>  cameron  <HYPHENS>  i'm at the mercy of a particularly hideous breed of loser <PERIOD>   my sister <PERIOD>   i can't date until she does <PERIOD> \", 'seems like she could get a date easy enough <PERIOD>  <PERIOD>  <PERIOD> ']]\n"
     ]
    }
   ],
   "source": [
    "# Lower the case and replace the tokens from all dialogues\n",
    "movie_dialogues = [[replace_tokens(line.lower()) for line in dialogue] for dialogue in movie_dialogues]\n",
    "\n",
    "print(movie_dialogues[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['can', 'we', 'make', 'this', 'quick', '<QUESTION_MARK>', 'roxanne', 'korrine', 'and', 'andrew', 'barrett', 'are', 'having', 'an', 'incredibly', 'horrendous', 'public', 'break-', 'up', 'on', 'the', 'quad', '<PERIOD>', 'again', '<PERIOD>', 'well', '<COMMA>', 'i', 'thought', \"we'd\", 'start', 'with', 'pronunciation', '<COMMA>', 'if', \"that's\", 'okay', 'with', 'you', '<PERIOD>', 'not', 'the', 'hacking', 'and', 'gagging', 'and', 'spitting', 'part', '<PERIOD>', 'please', '<PERIOD>', 'okay', '<PERIOD>', '<PERIOD>', '<PERIOD>', 'then', 'how', \"'bout\", 'we', 'try', 'out', 'some', 'french', 'cuisine', '<PERIOD>', 'saturday', '<QUESTION_MARK>', 'night', '<QUESTION_MARK>', \"you're\", 'asking', 'me', 'out', '<PERIOD>', \"that's\", 'so', 'cute', '<PERIOD>', \"what's\", 'your', 'name', 'again', '<QUESTION_MARK>', 'forget', 'it', '<PERIOD>', 'no', '<COMMA>', 'no', '<COMMA>', \"it's\", 'my', 'fault', '<HYPHENS>', 'we', \"didn't\", 'have', 'a', 'proper', 'introduction', '<HYPHENS>', '-', 'cameron', '<PERIOD>', 'the', 'thing', 'is', '<COMMA>', 'cameron', '<HYPHENS>', \"i'm\", 'at', 'the', 'mercy', 'of', 'a', 'particularly', 'hideous', 'breed', 'of', 'loser', '<PERIOD>', 'my', 'sister', '<PERIOD>', 'i', \"can't\", 'date', 'until', 'she', 'does', '<PERIOD>', 'seems', 'like', 'she', 'could', 'get', 'a', 'date', 'easy', 'enough', '<PERIOD>', '<PERIOD>', '<PERIOD>', 'why', '<QUESTION_MARK>', 'unsolved', 'mystery', '<PERIOD>', 'she', 'used', 'to', 'be', 'really', 'popular', 'when', 'she', 'started', 'high', 'school', '<COMMA>', 'then', 'it', 'was', 'just', 'like', 'she', 'got', 'sick', 'of', 'it', 'or', 'something', '<PERIOD>', \"that's\", 'a', 'shame', '<PERIOD>', 'gosh', '<COMMA>', 'if', 'only', 'we', 'could', 'find', 'kat', 'a', 'boyfriend', '<PERIOD>', '<PERIOD>', '<PERIOD>', 'let', 'me', 'see', 'what', 'i', 'can', 'do', '<PERIOD>', \"c'esc\"]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate all text\n",
    "all_lines = ' '.join([' '.join([line for line in dialogue]) for dialogue in movie_dialogues])\n",
    "\n",
    "# Get all words\n",
    "words = all_lines.split()\n",
    "\n",
    "print(words[:200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get all the unique words\n",
    "words_set = set(words)\n",
    "\n",
    "# Create the vocabularys\n",
    "vocab_to_int = {word: id for word, id in zip(words_set, range(4, len(words_set) + 4))}\n",
    "vocab_to_int['<PAD>'] = 0\n",
    "vocab_to_int['<EOS>'] = 1\n",
    "vocab_to_int['<UNK>'] = 2\n",
    "vocab_to_int['<GO>'] = 3\n",
    "\n",
    "int_to_vocab = {id: word for word, id in vocab_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of words in te vocabulary: 65192\n"
     ]
    }
   ],
   "source": [
    "# Get total number of words in the vocabulary\n",
    "n_words = len(vocab_to_int)\n",
    "\n",
    "print('Number of words in te vocabulary: {}'.format(n_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[43047, 34850, 25482, 44293, 57976, 29264, 39216, 19388, 59869, 41622, 16372, 54237, 1179, 57263, 16117, 33399, 2168, 45130, 26856, 14581, 37313, 21615, 23664, 27790, 23664], [45636, 14523, 57039, 30260, 49949, 39754, 9016, 6352, 14523, 35340, 20970, 24286, 9016, 45053, 23664], [50988, 37313, 32344, 59869, 52930, 59869, 53869, 53975, 23664, 17761, 23664], [24286, 23664, 23664, 23664, 42361, 59898, 11705, 34850, 63352, 14731, 7288, 41709, 19578, 23664, 20046, 29264, 64471, 29264]], [[47719, 65086, 19280, 14731, 23664, 20970, 6865, 48975, 23664, 45535, 22048, 7738, 27790, 29264], [19362, 15283, 23664]], [[12174, 14523, 12174, 14523, 48523, 4531, 54868, 45394, 34850, 46600, 53022, 14899, 25805, 35962, 45394, 19941], [47686, 23664], [37313, 36817, 13992, 14523, 47686, 45394, 29867, 53543, 37313, 56175, 43228, 14899, 53576, 25852, 50986, 43228, 61176, 23664, 4531, 49230, 23664, 57039, 42535, 39366, 50494, 55373, 37626, 23664], [11773, 25136, 55373, 18300, 3572, 14899, 39366, 16070, 35997, 23664, 23664, 23664]]]\n"
     ]
    }
   ],
   "source": [
    "# Convert the words in all dialogues to their ids\n",
    "movie_dialogues_int = [[[vocab_to_int[word] for word in line.split()] for line in dialogue] for dialogue in movie_dialogues]\n",
    "\n",
    "print(movie_dialogues_int[:3])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
